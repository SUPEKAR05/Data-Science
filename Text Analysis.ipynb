{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51cff9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KANCHAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\KANCHAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\KANCHAN\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ea06259",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_doc = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3616a67e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokens = word_tokenize(sample_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4e2d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS Tagging\n",
    "pos_tags = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e587726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8130de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d8d9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30634240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original document: \n",
      "Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n",
      "\n",
      "\n",
      "Tokenization: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n",
      "\n",
      "POS Tagging: [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('subfield', 'NN'), ('of', 'IN'), ('linguistics', 'NNS'), (',', ','), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('information', 'NN'), ('engineering', 'NN'), (',', ','), ('and', 'CC'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('concerned', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('interactions', 'NNS'), ('between', 'IN'), ('computers', 'NNS'), ('and', 'CC'), ('human', 'JJ'), ('(', '('), ('natural', 'JJ'), (')', ')'), ('languages', 'NNS'), (',', ','), ('in', 'IN'), ('particular', 'JJ'), ('how', 'WRB'), ('to', 'TO'), ('program', 'NN'), ('computers', 'NNS'), ('to', 'TO'), ('process', 'VB'), ('and', 'CC'), ('analyze', 'VB'), ('large', 'JJ'), ('amounts', 'NNS'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('data', 'NNS'), ('.', '.')]\n",
      "\n",
      "Filtered Tokens (Stopwords removal): ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'information', 'engineering', ',', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', '(', 'natural', ')', 'languages', ',', 'particular', 'program', 'computers', 'process', 'analyze', 'large', 'amounts', 'natural', 'language', 'data', '.']\n",
      "\n",
      "Stemmed Tokens: ['natur', 'languag', 'process', '(', 'nlp', ')', 'subfield', 'linguist', ',', 'comput', 'scienc', ',', 'inform', 'engin', ',', 'artifici', 'intellig', 'concern', 'interact', 'comput', 'human', '(', 'natur', ')', 'languag', ',', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', '.']\n",
      "\n",
      "Lemmatized Tokens: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'information', 'engineering', ',', 'artificial', 'intelligence', 'concerned', 'interaction', 'computer', 'human', '(', 'natural', ')', 'language', ',', 'particular', 'program', 'computer', 'process', 'analyze', 'large', 'amount', 'natural', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "# Print preprocessed results\n",
    "print(\"Original document:\", sample_doc)\n",
    "print(\"\\nTokenization:\", tokens)\n",
    "print(\"\\nPOS Tagging:\", pos_tags)\n",
    "print(\"\\nFiltered Tokens (Stopwords removal):\", filtered_tokens)\n",
    "print(\"\\nStemmed Tokens:\", stemmed_tokens)\n",
    "print(\"\\nLemmatized Tokens:\", lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68f1f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF-IDF representation\n",
    "corpus = [sample_doc]  # Create a list of documents (in this case, only one document)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2af74625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Representation:\n",
      "    amounts   analyze       and  artificial   between  computer  computers  \\\n",
      "0  0.128037  0.128037  0.384111    0.128037  0.128037  0.128037   0.256074   \n",
      "\n",
      "   concerned      data  engineering  ...        of  particular   process  \\\n",
      "0   0.128037  0.128037     0.128037  ...  0.256074    0.128037  0.128037   \n",
      "\n",
      "   processing   program   science  subfield       the        to      with  \n",
      "0    0.128037  0.128037  0.128037  0.128037  0.128037  0.256074  0.128037  \n",
      "\n",
      "[1 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert TF-IDF matrix to DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Representation:\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88e4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
